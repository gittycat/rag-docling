{% extends "base.html" %}

{% block title %}RAG System - About{% endblock %}

{% block body_class %}bg-gray-50 dark:bg-gray-900 min-h-screen transition-colors duration-200{% endblock %}

{% block nav_links %}
<a href="/" class="text-gray-600 hover:text-gray-900 dark:text-gray-300 dark:hover:text-gray-100 transition">Home</a>
<a href="/admin" class="text-gray-600 hover:text-gray-900 dark:text-gray-300 dark:hover:text-gray-100 transition">Admin</a>
<span class="text-gray-400 dark:text-gray-500 cursor-default">About</span>
{% endblock %}

{% block content %}
<main class="max-w-4xl mx-auto mt-24 px-4 sm:px-6 lg:px-8">
    <div class="bg-white dark:bg-gray-800 rounded-lg shadow-md p-8 transition-colors duration-200">
        <h1 class="text-3xl font-bold text-gray-900 dark:text-gray-100 mb-6">About this RAG System</h1>

        <div class="space-y-6 text-gray-700 dark:text-gray-300">
            <section>
                <h2 class="text-xl font-semibold text-gray-900 dark:text-gray-100 mb-3">Overview</h2>
                <p>
                    A fully local Retrieval Augmented Generation (RAG) system that keeps your data secure by running
                    entirely on your infrastructure. All document processing, embedding generation, and LLM inference
                    happen locally—no data is sent to external services. Search through your documents using natural
                    language queries with intelligent, context-aware answers powered by locally-hosted language models.
                </p>
            </section>

            <section>
                <h2 class="text-xl font-semibold text-gray-900 dark:text-gray-100 mb-3">Features</h2>
                <ul class="list-disc list-inside space-y-2">
                    <li>Conversational search with multi-turn context</li>
                    <li>Support for multiple file formats (PDF, DOCX, PPTX, XLSX, HTML, TXT, MD)</li>
                    <li>Two-stage retrieval with semantic reranking</li>
                    <li>Local deployment with privacy-first design</li>
                    <li>Real-time document processing with progress tracking</li>
                </ul>
            </section>

            <section>
                <h2 class="text-xl font-semibold text-gray-900 dark:text-gray-100 mb-3">LLM Models</h2>
                <div id="models-info" class="space-y-3">
                    <div class="flex items-center space-x-2">
                        <div class="animate-spin h-5 w-5 border-2 border-blue-500 border-t-transparent rounded-full"></div>
                        <span class="text-gray-500 dark:text-gray-400">Loading model information...</span>
                    </div>
                </div>
            </section>

            <section>
                <h2 class="text-xl font-semibold text-gray-900 dark:text-gray-100 mb-3">Technology Stack</h2>
                <div class="grid grid-cols-1 md:grid-cols-2 gap-4">
                    <div>
                        <h3 class="font-semibold text-gray-900 dark:text-gray-100 mb-2">Core Components</h3>
                        <ul class="space-y-1 text-sm">
                            <li>• LlamaIndex for orchestration</li>
                            <li>• ChromaDB for vector storage</li>
                            <li>• Docling for document parsing</li>
                            <li>• Celery + Redis for async processing</li>
                        </ul>
                    </div>
                    <div>
                        <h3 class="font-semibold text-gray-900 dark:text-gray-100 mb-2">Infrastructure</h3>
                        <ul class="space-y-1 text-sm">
                            <li>• FastAPI web framework</li>
                            <li>• Docker containerization</li>
                            <li>• Network isolation (public/private)</li>
                            <li>• Tailwind CSS for styling</li>
                        </ul>
                    </div>
                </div>
            </section>
        </div>
    </div>
</main>
{% endblock %}

{% block extra_scripts %}
<script>
async function loadModelsInfo() {
    try {
        const response = await fetch('/api/models/info');
        if (!response.ok) {
            throw new Error('Failed to fetch models info');
        }

        const data = await response.json();
        const container = document.getElementById('models-info');

        const inferenceValue = `${data.llm_model} - ${data.llm_hosting}`;
        const rerankerValue = data.reranker_enabled
            ? data.reranker_model
            : 'Disabled';

        container.innerHTML = `
            <ul class="space-y-2">
                <li><span class="text-gray-700 dark:text-gray-300">Inference Model: <span class="font-mono">${inferenceValue}</span></span></li>
                <li><span class="text-gray-700 dark:text-gray-300">Embedding Model: <span class="font-mono">${data.embedding_model}</span></span></li>
                <li><span class="text-gray-700 dark:text-gray-300">Reranker: <span class="font-mono">${rerankerValue}</span></span></li>
            </ul>
        `;
    } catch (error) {
        console.error('Error loading models info:', error);
        const container = document.getElementById('models-info');
        container.innerHTML = `
            <div class="text-red-600 dark:text-red-400">
                Failed to load model information. Please check if the RAG server is running.
            </div>
        `;
    }
}

// Load models info when page loads
document.addEventListener('DOMContentLoaded', loadModelsInfo);
</script>
{% endblock %}
